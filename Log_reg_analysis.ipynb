{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b950b07-4ee5-47d6-8a37-2196e38d3d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprocessed DataFrame:\n",
      "                                                Keyword  Source\n",
      "0     funny, point, get, results, involve, sorry, pr...       1\n",
      "1     funny, really, pen, finger, ink, someone, stic...       0\n",
      "2     touch, stressed, alcohol, emotions, breaths, c...       1\n",
      "3     alcohol, glad, enjoying, intake, feel, drink, ask       0\n",
      "4     person, seems, gullible, phone, tries, like, p...       1\n",
      "...                                                 ...     ...\n",
      "2455  information, first, dealer, find, need, could,...       0\n",
      "2456  think, important, legal, fellow, world, challe...       1\n",
      "2457  like, better, think, treating, would, stopped,...       0\n",
      "2458  try, best, might, answer, question, anyway, as...       1\n",
      "2459             beverly, hills, drive, ca, north, sure       0\n",
      "\n",
      "[2460 rows x 2 columns]\n",
      "\n",
      "Processed DataFrame:\n",
      "                                                Keyword  Source\n",
      "0     lively, whimsical, amusing, playful, satirical...       1\n",
      "1                          humorous, playful, whimsical       0\n",
      "2                              emotional, tips, calming       1\n",
      "3                  supportive, concerned, tone, curious       0\n",
      "4                        misleading, cunning, deceptive       1\n",
      "...                                                 ...     ...\n",
      "2455  unable, concerned, frusterated, annoyed, tone,...       0\n",
      "2456                 optimistic, empathetic, reflective       1\n",
      "2457  empowering, strong, expressing, defiant, criti...       0\n",
      "2458                      polite, concerned, persistent       1\n",
      "2459                          serious, confident, tense       0\n",
      "\n",
      "[2460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the input directory\n",
    "input_dir = \"output B\"\n",
    "\n",
    "# Get the list of CSV files in the input directory\n",
    "csv_files = [file for file in os.listdir(input_dir) if file.endswith(\".csv\")]\n",
    "\n",
    "# Find the highest numbered CSV file\n",
    "if csv_files:\n",
    "    latest_file = max(csv_files, key=lambda x: int(x.split(\"_\")[0]))\n",
    "    input_path = os.path.join(input_dir, latest_file)\n",
    "    df = pd.read_csv(input_path)\n",
    "else:\n",
    "    print(\"No CSV files found in the input directory.\")\n",
    "    exit()\n",
    "\n",
    "# Discard rows where C_Keywords is '~'\n",
    "df = df[df['C_Keywords'] != '~']\n",
    "\n",
    "# Create the first DataFrame (unprocessed)\n",
    "data_list_unprocessed = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    c_unique_list = eval(row['C_Unique_List'])\n",
    "    r_unique_list = eval(row['R_Unique_List'])\n",
    "    \n",
    "    data_list_unprocessed.append({'Keyword': ', '.join(c_unique_list), 'Source': 1})\n",
    "    data_list_unprocessed.append({'Keyword': ', '.join(r_unique_list), 'Source': 0})\n",
    "\n",
    "df_unprocessed = pd.DataFrame(data_list_unprocessed)\n",
    "\n",
    "# Create the second DataFrame (processed)\n",
    "data_list_processed = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if isinstance(row['C_Keywords_Unique'], str):\n",
    "        c_keywords_unique = row['C_Keywords_Unique'].split(', ')\n",
    "    else:\n",
    "        c_keywords_unique = []\n",
    "    \n",
    "    if isinstance(row['R_Keywords_Unique'], str):\n",
    "        r_keywords_unique = row['R_Keywords_Unique'].split(', ')\n",
    "    else:\n",
    "        r_keywords_unique = []\n",
    "    \n",
    "    data_list_processed.append({'Keyword': ', '.join(c_keywords_unique), 'Source': 1})\n",
    "    data_list_processed.append({'Keyword': ', '.join(r_keywords_unique), 'Source': 0})\n",
    "\n",
    "df_processed = pd.DataFrame(data_list_processed)\n",
    "\n",
    "# Print the DataFrames\n",
    "print(\"Unprocessed DataFrame:\")\n",
    "print(df_unprocessed)\n",
    "\n",
    "print(\"\\nProcessed DataFrame:\")\n",
    "print(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef1bb7b-1549-473d-b36d-e1a89bd9a970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Coefficients by Absolute Magnitude (Unprocessed Model):\n",
      "choice: -1.327749413058812\n",
      "humans: 1.2052426635741094\n",
      "quick: -1.1643989774121504\n",
      "depends: -1.1641307113028614\n",
      "alright: -1.153836272070192\n",
      "result: 1.1529395860460727\n",
      "conversation: 1.147279785310721\n",
      "ca: -1.1385399825454838\n",
      "call: 1.134710847142368\n",
      "whatever: -1.1278333647451908\n",
      "\n",
      "Top 10 Coefficients by Absolute Magnitude (Processed Model):\n",
      "reserved: 1.303971597671775\n",
      "emotional: 1.2905864879729863\n",
      "skeptically: -1.261087055920453\n",
      "request: 1.1939814055543314\n",
      "certain: 1.179597102230682\n",
      "better: 1.161258924879242\n",
      "inapprop: -1.1123469677395215\n",
      "seriously: 1.1107739100749179\n",
      "disbelief: -1.0970710205073257\n",
      "find: 1.0818256981590093\n",
      "\n",
      "Unprocessed Model Accuracy: 0.5060975609756098\n",
      "Processed Model Accuracy: 0.5691056910569106\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ... (previous code remains the same)\n",
    "\n",
    "# Perform logistic regression on the unprocessed DataFrame\n",
    "vectorizer_unprocessed = CountVectorizer()\n",
    "X_unprocessed = vectorizer_unprocessed.fit_transform(df_unprocessed['Keyword'])\n",
    "y_unprocessed = df_unprocessed['Source']\n",
    "\n",
    "X_train_unprocessed, X_test_unprocessed, y_train_unprocessed, y_test_unprocessed = train_test_split(\n",
    "    X_unprocessed, y_unprocessed, test_size=0.2, random_state=42)\n",
    "\n",
    "model_unprocessed = LogisticRegression()\n",
    "model_unprocessed.fit(X_train_unprocessed, y_train_unprocessed)\n",
    "y_pred_unprocessed = model_unprocessed.predict(X_test_unprocessed)\n",
    "\n",
    "accuracy_unprocessed = accuracy_score(y_test_unprocessed, y_pred_unprocessed)\n",
    "\n",
    "# Output the top 10 coefficients by absolute magnitude for the unprocessed model\n",
    "feature_names_unprocessed = vectorizer_unprocessed.get_feature_names_out()\n",
    "coef_unprocessed = model_unprocessed.coef_[0]\n",
    "top_indices_unprocessed = np.argsort(np.abs(coef_unprocessed))[-10:][::-1]\n",
    "print(\"Top 10 Coefficients by Absolute Magnitude (Unprocessed Model):\")\n",
    "for index in top_indices_unprocessed:\n",
    "    print(f\"{feature_names_unprocessed[index]}: {coef_unprocessed[index]}\")\n",
    "print()\n",
    "\n",
    "# Perform logistic regression on the processed DataFrame\n",
    "vectorizer_processed = CountVectorizer()\n",
    "X_processed = vectorizer_processed.fit_transform(df_processed['Keyword'])\n",
    "y_processed = df_processed['Source']\n",
    "\n",
    "X_train_processed, X_test_processed, y_train_processed, y_test_processed = train_test_split(\n",
    "    X_processed, y_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "model_processed = LogisticRegression()\n",
    "model_processed.fit(X_train_processed, y_train_processed)\n",
    "y_pred_processed = model_processed.predict(X_test_processed)\n",
    "\n",
    "accuracy_processed = accuracy_score(y_test_processed, y_pred_processed)\n",
    "\n",
    "# Output the top 10 coefficients by absolute magnitude for the processed model\n",
    "feature_names_processed = vectorizer_processed.get_feature_names_out()\n",
    "coef_processed = model_processed.coef_[0]\n",
    "top_indices_processed = np.argsort(np.abs(coef_processed))[-10:][::-1]\n",
    "print(\"Top 10 Coefficients by Absolute Magnitude (Processed Model):\")\n",
    "for index in top_indices_processed:\n",
    "    print(f\"{feature_names_processed[index]}: {coef_processed[index]}\")\n",
    "print()\n",
    "\n",
    "# Compare the accuracy of unprocessed and processed models\n",
    "print(\"Unprocessed Model Accuracy:\", accuracy_unprocessed)\n",
    "print(\"Processed Model Accuracy:\", accuracy_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3f550-d5d1-4a22-a3c9-49cecedb7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
